{"version":3,"sources":["~lib/rt/common.ts","~lib/rt/tlsf.ts","~lib/shared/typeinfo.ts","~lib/rt/itcms.ts","asm/index.ts"],"names":[],"mappings":"0FIGE,AAAO,EAAE,GAAI,EAAE","sourceRoot":"./index.debug.wasm","sourcesContent":["// Alignment guarantees\n\n// @ts-ignore: decorator\n@inline export const AL_BITS: u32 = 4; // 16 bytes to fit up to v128\n// @ts-ignore: decorator\n@inline export const AL_SIZE: usize = 1 << <usize>AL_BITS;\n// @ts-ignore: decorator\n@inline export const AL_MASK: usize = AL_SIZE - 1;\n\n// Extra debugging\n\n// @ts-ignore: decorator\n@inline export const DEBUG = true;\n// @ts-ignore: decorator\n@inline export const TRACE = false;\n// @ts-ignore: decorator\n@inline export const RTRACE = isDefined(ASC_RTRACE);\n// @ts-ignore: decorator\n@inline export const PROFILE = isDefined(ASC_PROFILE);\n\n// Memory manager\n\n// ╒════════════ Memory manager block layout (32-bit) ═════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤\n// │                           MM info                             │ -4\n// ╞>ptr═══════════════════════════════════════════════════════════╡\n// │                              ...                              │\n@unmanaged export class BLOCK {\n  /** Memory manager info. */\n  mmInfo: usize;\n}\n\n/** Overhead of a memory manager block. */\n// @ts-ignore: decorator\n@inline export const BLOCK_OVERHEAD: usize = offsetof<BLOCK>();\n\n/** Maximum size of a memory manager block's payload. */\n// @ts-ignore: decorator\n@inline export const BLOCK_MAXSIZE: usize = (1 << 30) - BLOCK_OVERHEAD;\n\n// Garbage collector\n\n// ╒══════════ Garbage collector object layout (32-bit) ═══════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤\n// │                     Memory manager block                      │ -20\n// ╞═══════════════════════════════════════════════════════════════╡\n// │                            GC info                            │ -16\n// ├───────────────────────────────────────────────────────────────┤\n// │                            GC info                            │ -12\n// ├───────────────────────────────────────────────────────────────┤\n// │                            RT id                              │ -8\n// ├───────────────────────────────────────────────────────────────┤\n// │                            RT size                            │ -4\n// ╞>ptr═══════════════════════════════════════════════════════════╡\n// │                              ...                              │\n@unmanaged export class OBJECT extends BLOCK {\n  /** Garbage collector info. */\n  gcInfo: u32;\n  /** Garbage collector info. */\n  gcInfo2: u32;\n  /** Runtime class id. */\n  rtId: u32;\n  /** Runtime object size. */\n  rtSize: u32;\n}\n\n/** Overhead of a garbage collector object. Excludes memory manager block overhead. */\n// @ts-ignore: decorator\n@inline export const OBJECT_OVERHEAD: usize = (offsetof<OBJECT>() - BLOCK_OVERHEAD + AL_MASK) & ~AL_MASK;\n\n/** Maximum size of a garbage collector object's payload. */\n// @ts-ignore: decorator\n@inline export const OBJECT_MAXSIZE: usize = BLOCK_MAXSIZE - OBJECT_OVERHEAD;\n\n/** Total of memory manager and garbage collector overhead. */\n// @ts-ignore: decorator\n@inline export const TOTAL_OVERHEAD: usize = BLOCK_OVERHEAD + OBJECT_OVERHEAD;\n","import { AL_BITS, AL_SIZE, AL_MASK, DEBUG, BLOCK, BLOCK_OVERHEAD, BLOCK_MAXSIZE } from \"./common\";\nimport { oninit, onalloc, onresize, onmove, onfree } from \"./rtrace\";\nimport { E_ALLOCATION_TOO_LARGE } from \"../util/error\";\n\n// === The TLSF (Two-Level Segregate Fit) memory allocator ===\n// see: http://www.gii.upv.es/tlsf/\n\n// - `ffs(x)` is equivalent to `ctz(x)` with x != 0\n// - `fls(x)` is equivalent to `sizeof(x) * 8 - clz(x) - 1`\n\n// ╒══════════════ Block size interpretation (32-bit) ═════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┼─┴─┴─┴─╫─┴─┴─┴─┤\n// │ |                    FL                       │ SB = SL + AL  │ ◄─ usize\n// └───────────────────────────────────────────────┴───────╨───────┘\n// FL: first level, SL: second level, AL: alignment, SB: small block\n\n// @ts-ignore: decorator\n@inline const SL_BITS: u32 = 4;\n// @ts-ignore: decorator\n@inline const SL_SIZE: u32 = 1 << SL_BITS;\n\n// @ts-ignore: decorator\n@inline const SB_BITS: u32 = SL_BITS + AL_BITS;\n// @ts-ignore: decorator\n@inline const SB_SIZE: u32 = 1 << SB_BITS;\n\n// @ts-ignore: decorator\n@inline const FL_BITS: u32 = 31 - SB_BITS;\n\n// [00]: < 256B (SB)  [12]: < 1M\n// [01]: < 512B       [13]: < 2M\n// [02]: < 1K         [14]: < 4M\n// [03]: < 2K         [15]: < 8M\n// [04]: < 4K         [16]: < 16M\n// [05]: < 8K         [17]: < 32M\n// [06]: < 16K        [18]: < 64M\n// [07]: < 32K        [19]: < 128M\n// [08]: < 64K        [20]: < 256M\n// [09]: < 128K       [21]: < 512M\n// [10]: < 256K       [22]: <= 1G - OVERHEAD\n// [11]: < 512K\n// VMs limit to 2GB total (currently), making one 1G block max (or three 512M etc.) due to block overhead\n\n// Tags stored in otherwise unused alignment bits\n\n// @ts-ignore: decorator\n@inline const FREE: usize = 1 << 0;\n// @ts-ignore: decorator\n@inline const LEFTFREE: usize = 1 << 1;\n// @ts-ignore: decorator\n@inline const TAGS_MASK: usize = FREE | LEFTFREE; // <= AL_MASK\n\n// ╒════════════════════ Block layout (32-bit) ════════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┼─┼─┤            ┐\n// │                          size                             │L│F│ ◄─┐ info   overhead\n// ╞>ptr═══════════════════════════════════════════════════════╧═╧═╡   │        ┘\n// │                        if free: ◄ prev                        │ ◄─┤ usize\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                        if free: next ►                        │ ◄─┤\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                             ...                               │   │ >= 0\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                        if free: back ▲                        │ ◄─┘\n// └───────────────────────────────────────────────────────────────┘ >= MIN SIZE\n// F: FREE, L: LEFTFREE\n@unmanaged export class Block extends BLOCK {\n\n  /** Previous free block, if any. Only valid if free, otherwise part of payload. */\n  prev: Block | null;\n  /** Next free block, if any. Only valid if free, otherwise part of payload. */\n  next: Block | null;\n\n  // If the block is free, there is a 'back'reference at its end pointing at its start.\n}\n\n// Block constants. A block must have a minimum size of three pointers so it can hold `prev`,\n// `next` and `back` if free.\n\n// @ts-ignore: decorator\n@inline const BLOCK_MINSIZE: usize = ((3 * sizeof<usize>() + BLOCK_OVERHEAD + AL_MASK) & ~AL_MASK) - BLOCK_OVERHEAD; // prev + next + back\n// @ts-ignore: decorator\n// @inline const BLOCK_MAXSIZE: usize = 1 << (FL_BITS + SB_BITS - 1); // exclusive, lives in common.ts\n\n/** Gets the left block of a block. Only valid if the left block is free. */\n// @ts-ignore: decorator\n@inline function GETFREELEFT(block: Block): Block {\n  return load<Block>(changetype<usize>(block) - sizeof<usize>());\n}\n\n/** Gets the right block of a block by advancing to the right by its size. */\n// @ts-ignore: decorator\n@inline function GETRIGHT(block: Block): Block {\n  return changetype<Block>(changetype<usize>(block) + BLOCK_OVERHEAD + (block.mmInfo & ~TAGS_MASK));\n}\n\n// ╒═════════════════════ Root layout (32-bit) ════════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤          ┐\n// │        0        |           flMap                            S│ ◄────┐\n// ╞═══════════════════════════════════════════════════════════════╡      │\n// │                           slMap[0] S                          │ ◄─┐  │\n// ├───────────────────────────────────────────────────────────────┤   │  │\n// │                           slMap[1]                            │ ◄─┤  │\n// ├───────────────────────────────────────────────────────────────┤  u32 │\n// │                           slMap[22]                           │ ◄─┘  │\n// ╞═══════════════════════════════════════════════════════════════╡    usize\n// │                            head[0]                            │ ◄────┤\n// ├───────────────────────────────────────────────────────────────┤      │\n// │                              ...                              │ ◄────┤\n// ├───────────────────────────────────────────────────────────────┤      │\n// │                           head[367]                           │ ◄────┤\n// ╞═══════════════════════════════════════════════════════════════╡      │\n// │                             tail                              │ ◄────┘\n// └───────────────────────────────────────────────────────────────┘   SIZE   ┘\n// S: Small blocks map\n@unmanaged class Root {\n  /** First level bitmap. */\n  flMap: usize;\n}\n\n// Root constants. Where stuff is stored inside of the root structure.\n\n// @ts-ignore: decorator\n@inline const SL_START: usize = sizeof<usize>();\n// @ts-ignore: decorator\n@inline const SL_END: usize = SL_START + (FL_BITS << alignof<u32>());\n// @ts-ignore: decorator\n@inline const HL_START: usize = (SL_END + AL_MASK) & ~AL_MASK;\n// @ts-ignore: decorator\n@inline const HL_END: usize = HL_START + FL_BITS * SL_SIZE * sizeof<usize>();\n// @ts-ignore: decorator\n@inline const ROOT_SIZE: usize = HL_END + sizeof<usize>();\n\n// @ts-ignore: decorator\n@lazy export var ROOT: Root;\n\n/** Gets the second level map of the specified first level. */\n// @ts-ignore: decorator\n@inline function GETSL(root: Root, fl: usize): u32 {\n  return load<u32>(\n    changetype<usize>(root) + (fl << alignof<u32>()),\n    SL_START\n  );\n}\n\n/** Sets the second level map of the specified first level. */\n// @ts-ignore: decorator\n@inline function SETSL(root: Root, fl: usize, slMap: u32): void {\n  store<u32>(\n    changetype<usize>(root) + (fl << alignof<u32>()),\n    slMap,\n    SL_START\n  );\n}\n\n/** Gets the head of the free list for the specified combination of first and second level. */\n// @ts-ignore: decorator\n@inline function GETHEAD(root: Root, fl: usize, sl: u32): Block | null {\n  return load<Block>(\n    changetype<usize>(root) + (((fl << SL_BITS) + <usize>sl) << alignof<usize>()),\n    HL_START\n  );\n}\n\n/** Sets the head of the free list for the specified combination of first and second level. */\n// @ts-ignore: decorator\n@inline function SETHEAD(root: Root, fl: usize, sl: u32, head: Block | null): void {\n  store<Block | null>(\n    changetype<usize>(root) + (((fl << SL_BITS) + <usize>sl) << alignof<usize>()),\n    head,\n    HL_START\n  );\n}\n\n/** Gets the tail block.. */\n// @ts-ignore: decorator\n@inline function GETTAIL(root: Root): Block {\n  return load<Block>(\n    changetype<usize>(root),\n    HL_END\n  );\n}\n\n/** Sets the tail block. */\n// @ts-ignore: decorator\n@inline function SETTAIL(root: Root, tail: Block): void {\n  store<Block>(\n    changetype<usize>(root),\n    tail,\n    HL_END\n  );\n}\n\n/** Inserts a previously used block back into the free list. */\nfunction insertBlock(root: Root, block: Block): void {\n  if (DEBUG) assert(block); // cannot be null\n  var blockInfo = block.mmInfo;\n  if (DEBUG) assert(blockInfo & FREE); // must be free\n\n  var right = GETRIGHT(block);\n  var rightInfo = right.mmInfo;\n\n  // merge with right block if also free\n  if (rightInfo & FREE) {\n    let newSize = (blockInfo & ~TAGS_MASK) + BLOCK_OVERHEAD + (rightInfo & ~TAGS_MASK);\n    if (newSize < BLOCK_MAXSIZE) {\n      removeBlock(root, right);\n      block.mmInfo = blockInfo = (blockInfo & TAGS_MASK) | newSize;\n      right = GETRIGHT(block);\n      rightInfo = right.mmInfo;\n      // 'back' is set below\n    }\n  }\n\n  // merge with left block if also free\n  if (blockInfo & LEFTFREE) {\n    let left = GETFREELEFT(block);\n    let leftInfo = left.mmInfo;\n    if (DEBUG) assert(leftInfo & FREE); // must be free according to right tags\n    let newSize = (leftInfo & ~TAGS_MASK) + BLOCK_OVERHEAD + (blockInfo & ~TAGS_MASK);\n    if (newSize < BLOCK_MAXSIZE) {\n      removeBlock(root, left);\n      left.mmInfo = blockInfo = (leftInfo & TAGS_MASK) | newSize;\n      block = left;\n      // 'back' is set below\n    }\n  }\n\n  right.mmInfo = rightInfo | LEFTFREE;\n  // reference to right is no longer used now, hence rightInfo is not synced\n\n  // we now know the size of the block\n  var size = blockInfo & ~TAGS_MASK;\n  if (DEBUG) assert(size >= BLOCK_MINSIZE && size < BLOCK_MAXSIZE); // must be a valid size\n  if (DEBUG) assert(changetype<usize>(block) + BLOCK_OVERHEAD + size == changetype<usize>(right)); // must match\n\n  // set 'back' to itself at the end of block\n  store<Block>(changetype<usize>(right) - sizeof<usize>(), block);\n\n  // mapping_insert\n  var fl: usize, sl: u32;\n  if (size < SB_SIZE) {\n    fl = 0;\n    sl = <u32>(size >> AL_BITS);\n  } else {\n    const inv: usize = sizeof<usize>() * 8 - 1;\n    fl = inv - clz<usize>(size);\n    sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n    fl -= SB_BITS - 1;\n  }\n  if (DEBUG) assert(fl < FL_BITS && sl < SL_SIZE); // fl/sl out of range\n\n  // perform insertion\n  var head = GETHEAD(root, fl, sl);\n  block.prev = null;\n  block.next = head;\n  if (head) head.prev = block;\n  SETHEAD(root, fl, sl, block);\n\n  // update first and second level maps\n  root.flMap |= (1 << fl);\n  SETSL(root, fl, GETSL(root, fl) | (1 << sl));\n}\n\n/** Removes a free block from internal lists. */\nfunction removeBlock(root: Root, block: Block): void {\n  var blockInfo = block.mmInfo;\n  if (DEBUG) assert(blockInfo & FREE); // must be free\n  var size = blockInfo & ~TAGS_MASK;\n  if (DEBUG) assert(size >= BLOCK_MINSIZE && size < BLOCK_MAXSIZE); // must be valid\n\n  // mapping_insert\n  var fl: usize, sl: u32;\n  if (size < SB_SIZE) {\n    fl = 0;\n    sl = <u32>(size >> AL_BITS);\n  } else {\n    const inv: usize = sizeof<usize>() * 8 - 1;\n    fl = inv - clz<usize>(size);\n    sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n    fl -= SB_BITS - 1;\n  }\n  if (DEBUG) assert(fl < FL_BITS && sl < SL_SIZE); // fl/sl out of range\n\n  // link previous and next free block\n  var prev = block.prev;\n  var next = block.next;\n  if (prev) prev.next = next;\n  if (next) next.prev = prev;\n\n  // update head if we are removing it\n  if (block == GETHEAD(root, fl, sl)) {\n    SETHEAD(root, fl, sl, next);\n\n    // clear second level map if head is empty now\n    if (!next) {\n      let slMap = GETSL(root, fl);\n      SETSL(root, fl, slMap &= ~(1 << sl));\n\n      // clear first level map if second level is empty now\n      if (!slMap) root.flMap &= ~(1 << fl);\n    }\n  }\n  // note: does not alter left/back because it is likely that splitting\n  // is performed afterwards, invalidating those changes. so, the caller\n  // must perform those updates.\n}\n\n/** Searches for a free block of at least the specified size. */\nfunction searchBlock(root: Root, size: usize): Block | null {\n  // size was already asserted by caller\n\n  // mapping_search\n  var fl: usize, sl: u32;\n  if (size < SB_SIZE) {\n    fl = 0;\n    sl = <u32>(size >> AL_BITS);\n  } else {\n    const halfMaxSize = BLOCK_MAXSIZE >> 1; // don't round last fl\n    const inv: usize = sizeof<usize>() * 8 - 1;\n    const invRound = inv - SL_BITS;\n    let requestSize = size < halfMaxSize\n      ? size + (1 << (invRound - clz<usize>(size))) - 1\n      : size;\n    fl = inv - clz<usize>(requestSize);\n    sl = <u32>((requestSize >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n    fl -= SB_BITS - 1;\n  }\n  if (DEBUG) assert(fl < FL_BITS && sl < SL_SIZE); // fl/sl out of range\n\n  // search second level\n  var slMap = GETSL(root, fl) & (~0 << sl);\n  var head: Block | null = null;\n  if (!slMap) {\n    // search next larger first level\n    let flMap = root.flMap & (~0 << (fl + 1));\n    if (!flMap) {\n      head = null;\n    } else {\n      fl = ctz<usize>(flMap);\n      slMap = GETSL(root, fl);\n      if (DEBUG) assert(slMap);  // can't be zero if fl points here\n      head = GETHEAD(root, fl, ctz<u32>(slMap));\n    }\n  } else {\n    head = GETHEAD(root, fl, ctz<u32>(slMap));\n  }\n  return head;\n}\n\n/** Prepares the specified block before (re-)use, possibly splitting it. */\nfunction prepareBlock(root: Root, block: Block, size: usize): void {\n  // size was already asserted by caller\n\n  var blockInfo = block.mmInfo;\n  if (DEBUG) assert(!((size + BLOCK_OVERHEAD) & AL_MASK)); // size must be aligned so the new block is\n\n  // split if the block can hold another MINSIZE block incl. overhead\n  var remaining = (blockInfo & ~TAGS_MASK) - size;\n  if (remaining >= BLOCK_OVERHEAD + BLOCK_MINSIZE) {\n    block.mmInfo = size | (blockInfo & LEFTFREE); // also discards FREE\n\n    let spare = changetype<Block>(changetype<usize>(block) + BLOCK_OVERHEAD + size);\n    spare.mmInfo = (remaining - BLOCK_OVERHEAD) | FREE; // not LEFTFREE\n    insertBlock(root, spare); // also sets 'back'\n\n  // otherwise tag block as no longer FREE and right as no longer LEFTFREE\n  } else {\n    block.mmInfo = blockInfo & ~FREE;\n    GETRIGHT(block).mmInfo &= ~LEFTFREE;\n  }\n}\n\n/** Adds more memory to the pool. */\nfunction addMemory(root: Root, start: usize, end: usize): bool {\n  if (DEBUG) assert(start <= end); // must be valid\n  start = ((start + BLOCK_OVERHEAD + AL_MASK) & ~AL_MASK) - BLOCK_OVERHEAD;\n  end &= ~AL_MASK;\n\n  var tail = GETTAIL(root);\n  var tailInfo: usize = 0;\n  if (tail) { // more memory\n    if (DEBUG) assert(start >= changetype<usize>(tail) + BLOCK_OVERHEAD);\n\n    // merge with current tail if adjacent\n    const offsetToTail = AL_SIZE;\n    if (start - offsetToTail == changetype<usize>(tail)) {\n      start -= offsetToTail;\n      tailInfo = tail.mmInfo;\n    } else {\n      // We don't do this, but a user might `memory.grow` manually\n      // leading to non-adjacent pages managed by TLSF.\n    }\n\n  } else if (DEBUG) { // first memory\n    assert(start >= changetype<usize>(root) + ROOT_SIZE); // starts after root\n  }\n\n  // check if size is large enough for a free block and the tail block\n  var size = end - start;\n  if (size < BLOCK_OVERHEAD + BLOCK_MINSIZE + BLOCK_OVERHEAD) {\n    return false;\n  }\n\n  // left size is total minus its own and the zero-length tail's header\n  var leftSize = size - 2 * BLOCK_OVERHEAD;\n  var left = changetype<Block>(start);\n  left.mmInfo = leftSize | FREE | (tailInfo & LEFTFREE);\n  left.prev = null;\n  left.next = null;\n\n  // tail is a zero-length used block\n  tail = changetype<Block>(start + BLOCK_OVERHEAD + leftSize);\n  tail.mmInfo = 0 | LEFTFREE;\n  SETTAIL(root, tail);\n\n  insertBlock(root, left); // also merges with free left before tail / sets 'back'\n\n  return true;\n}\n\n/** Grows memory to fit at least another block of the specified size. */\nfunction growMemory(root: Root, size: usize): void {\n  if (ASC_LOW_MEMORY_LIMIT) {\n    unreachable();\n    return;\n  }\n  // Here, both rounding performed in searchBlock ...\n  const halfMaxSize = BLOCK_MAXSIZE >> 1;\n  if (size < halfMaxSize) { // don't round last fl\n    const invRound = (sizeof<usize>() * 8 - 1) - SL_BITS;\n    size += (1 << (invRound - clz<usize>(size))) - 1;\n  }\n  // and additional BLOCK_OVERHEAD must be taken into account. If we are going\n  // to merge with the tail block, that's one time, otherwise it's two times.\n  var pagesBefore = memory.size();\n  size += BLOCK_OVERHEAD << usize((<usize>pagesBefore << 16) - BLOCK_OVERHEAD != changetype<usize>(GETTAIL(root)));\n  var pagesNeeded = <i32>(((size + 0xffff) & ~0xffff) >>> 16);\n  var pagesWanted = max(pagesBefore, pagesNeeded); // double memory\n  if (memory.grow(pagesWanted) < 0) {\n    if (memory.grow(pagesNeeded) < 0) unreachable();\n  }\n  var pagesAfter = memory.size();\n  addMemory(root, <usize>pagesBefore << 16, <usize>pagesAfter << 16);\n}\n\n/** Computes the size (excl. header) of a block. */\nfunction computeSize(size: usize): usize {\n  // Size must be large enough and aligned minus preceeding overhead\n  return size <= BLOCK_MINSIZE\n    ? BLOCK_MINSIZE\n    : ((size + BLOCK_OVERHEAD + AL_MASK) & ~AL_MASK) - BLOCK_OVERHEAD;\n}\n\n/** Prepares and checks an allocation size. */\nfunction prepareSize(size: usize): usize {\n  if (size >= BLOCK_MAXSIZE) throw new Error(E_ALLOCATION_TOO_LARGE);\n  return computeSize(size);\n}\n\n/** Initializes the root structure. */\nfunction initialize(): void {\n  if (isDefined(ASC_RTRACE)) oninit(__heap_base);\n  var rootOffset = (__heap_base + AL_MASK) & ~AL_MASK;\n  var pagesBefore = memory.size();\n  var pagesNeeded = <i32>((((rootOffset + ROOT_SIZE) + 0xffff) & ~0xffff) >>> 16);\n  if (pagesNeeded > pagesBefore && memory.grow(pagesNeeded - pagesBefore) < 0) unreachable();\n  var root = changetype<Root>(rootOffset);\n  root.flMap = 0;\n  SETTAIL(root, changetype<Block>(0));\n  for (let fl: usize = 0; fl < FL_BITS; ++fl) {\n    SETSL(root, fl, 0);\n    for (let sl: u32 = 0; sl < SL_SIZE; ++sl) {\n      SETHEAD(root, fl, sl, null);\n    }\n  }\n  var memStart = rootOffset + ROOT_SIZE;\n  if (ASC_LOW_MEMORY_LIMIT) {\n    const memEnd = <usize>ASC_LOW_MEMORY_LIMIT & ~AL_MASK;\n    if (memStart <= memEnd) addMemory(root, memStart, memEnd);\n    else unreachable(); // low memory limit already exceeded\n  } else {\n    addMemory(root, memStart, memory.size() << 16);\n  }\n  ROOT = root;\n}\n\n/** Allocates a block of the specified size. */\nexport function allocateBlock(root: Root, size: usize): Block {\n  var payloadSize = prepareSize(size);\n  var block = searchBlock(root, payloadSize);\n  if (!block) {\n    growMemory(root, payloadSize);\n    block = changetype<Block>(searchBlock(root, payloadSize));\n    if (DEBUG) assert(block); // must be found now\n  }\n  if (DEBUG) assert((block.mmInfo & ~TAGS_MASK) >= payloadSize); // must fit\n  removeBlock(root, <Block>block);\n  prepareBlock(root, <Block>block, payloadSize);\n  if (isDefined(ASC_RTRACE)) onalloc(block);\n  return <Block>block;\n}\n\n/** Reallocates a block to the specified size. */\nexport function reallocateBlock(root: Root, block: Block, size: usize): Block {\n  var payloadSize = prepareSize(size);\n  var blockInfo = block.mmInfo;\n  var blockSize = blockInfo & ~TAGS_MASK;\n\n  // possibly split and update runtime size if it still fits\n  if (payloadSize <= blockSize) {\n    prepareBlock(root, block, payloadSize);\n    if (isDefined(ASC_RTRACE)) {\n      if (payloadSize != blockSize) onresize(block, BLOCK_OVERHEAD + blockSize);\n    }\n    return block;\n  }\n\n  // merge with right free block if merger is large enough\n  var right = GETRIGHT(block);\n  var rightInfo = right.mmInfo;\n  if (rightInfo & FREE) {\n    let mergeSize = blockSize + BLOCK_OVERHEAD + (rightInfo & ~TAGS_MASK);\n    if (mergeSize >= payloadSize) {\n      removeBlock(root, right);\n      // TODO: this can yield an intermediate block larger than BLOCK_MAXSIZE, which\n      // is immediately split though. does this trigger any assertions / issues?\n      block.mmInfo = (blockInfo & TAGS_MASK) | mergeSize;\n      prepareBlock(root, block, payloadSize);\n      if (isDefined(ASC_RTRACE)) onresize(block, BLOCK_OVERHEAD + blockSize);\n      return block;\n    }\n  }\n\n  // otherwise move the block\n  return moveBlock(root, block, size);\n}\n\n/** Moves a block to a new one of the specified size. */\nfunction moveBlock(root: Root, block: Block, newSize: usize): Block {\n  var newBlock = allocateBlock(root, newSize);\n  memory.copy(changetype<usize>(newBlock) + BLOCK_OVERHEAD, changetype<usize>(block) + BLOCK_OVERHEAD, block.mmInfo & ~TAGS_MASK);\n  if (changetype<usize>(block) >= __heap_base) {\n    if (isDefined(ASC_RTRACE)) onmove(block, newBlock);\n    freeBlock(root, block);\n  }\n  return newBlock;\n}\n\n/** Frees a block. */\nexport function freeBlock(root: Root, block: Block): void {\n  if (isDefined(ASC_RTRACE)) onfree(block);\n  block.mmInfo = block.mmInfo | FREE;\n  insertBlock(root, block);\n}\n\n/** Checks that a used block is valid to be freed or reallocated. */\nfunction checkUsedBlock(ptr: usize): Block {\n  var block = changetype<Block>(ptr - BLOCK_OVERHEAD);\n  assert(\n    ptr != 0 && !(ptr & AL_MASK) &&  // must exist and be aligned\n    !(block.mmInfo & FREE)           // must be used\n  );\n  return block;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __alloc(size: usize): usize {\n  if (!ROOT) initialize();\n  return changetype<usize>(allocateBlock(ROOT, size)) + BLOCK_OVERHEAD;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __realloc(ptr: usize, size: usize): usize {\n  if (!ROOT) initialize();\n  return (ptr < __heap_base\n    ? changetype<usize>(moveBlock(ROOT, checkUsedBlock(ptr), size))\n    : changetype<usize>(reallocateBlock(ROOT, checkUsedBlock(ptr), size))\n  ) + BLOCK_OVERHEAD;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __free(ptr: usize): void {\n  if (ptr < __heap_base) return;\n  if (!ROOT) initialize();\n  freeBlock(ROOT, checkUsedBlock(ptr));\n}\n","// This file is shared with the compiler and must remain portable\n\n// ╒═══════════════════ Typeinfo interpretation ═══════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤ ◄─ __rtti_base\n// │                             count                             │\n// ╞═══════════════════════════════════════════════════════════════╡ ┐\n// │                      Typeinfo#flags [id=0]                    │ id < count\n// ├ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤\n// │                      Typeinfo#base  [id=0]                    │\n// ├───────────────────────────────────────────────────────────────┤\n// │                              ...                              │\n\n/** Runtime type information data structure. */\n@unmanaged\nexport class Typeinfo {\n  /** Flags describing the shape of this class type. */\n  flags: TypeinfoFlags = TypeinfoFlags.NONE;\n  /** Base class id or `0` if none. */\n  base: u32 = 0;\n}\n\n/** Runtime type information flags. */\nexport const enum TypeinfoFlags {\n  /** No specific flags. */\n  NONE = 0,\n  /** Type is an `ArrayBufferView`. */\n  ARRAYBUFFERVIEW = 1 << 0,\n  /** Type is an `Array`. */\n  ARRAY = 1 << 1,\n  /** Type is a `StaticArray`. */\n  STATICARRAY = 1 << 2,\n  /** Type is a `Set`. */\n  SET = 1 << 3,\n  /** Type is a `Map`. */\n  MAP = 1 << 4,\n  /** Type has no outgoing pointers. */\n  POINTERFREE = 1 << 5,\n  /** Value alignment of 1 byte. */\n  VALUE_ALIGN_0 = 1 << 6,\n  /** Value alignment of 2 bytes. */\n  VALUE_ALIGN_1 = 1 << 7,\n  /** Value alignment of 4 bytes. */\n  VALUE_ALIGN_2 = 1 << 8,\n  /** Value alignment of 8 bytes. */\n  VALUE_ALIGN_3 = 1 << 9,\n  /** Value alignment of 16 bytes. */\n  VALUE_ALIGN_4 = 1 << 10,\n  /** Value is a signed type. */\n  VALUE_SIGNED = 1 << 11,\n  /** Value is a float type. */\n  VALUE_FLOAT = 1 << 12,\n  /** Value type is nullable. */\n  VALUE_NULLABLE = 1 << 13,\n  /** Value type is managed. */\n  VALUE_MANAGED = 1 << 14,\n  /** Key alignment of 1 byte. */\n  KEY_ALIGN_0 = 1 << 15,\n  /** Key alignment of 2 bytes. */\n  KEY_ALIGN_1 = 1 << 16,\n  /** Key alignment of 4 bytes. */\n  KEY_ALIGN_2 = 1 << 17,\n  /** Key alignment of 8 bytes. */\n  KEY_ALIGN_3 = 1 << 18,\n  /** Key alignment of 16 bytes. */\n  KEY_ALIGN_4 = 1 << 19,\n  /** Key is a signed type. */\n  KEY_SIGNED = 1 << 20,\n  /** Key is a float type. */\n  KEY_FLOAT = 1 << 21,\n  /** Key type is nullable. */\n  KEY_NULLABLE = 1 << 22,\n  /** Key type is managed. */\n  KEY_MANAGED = 1 << 23\n}\n","import { BLOCK, BLOCK_OVERHEAD, OBJECT_OVERHEAD, OBJECT_MAXSIZE, TOTAL_OVERHEAD, DEBUG, TRACE, RTRACE, PROFILE } from \"./common\";\nimport { onvisit, oncollect, oninterrupt, onyield } from \"./rtrace\";\nimport { TypeinfoFlags } from \"../shared/typeinfo\";\nimport { E_ALLOCATION_TOO_LARGE, E_ALREADY_PINNED, E_NOT_PINNED } from \"../util/error\";\n\n// === ITCMS: An incremental Tri-Color Mark & Sweep garbage collector ===\n// Adapted from Bach Le's μgc, see: https://github.com/bullno1/ugc\n\n// ╒═════════════╤══════════════ Colors ═══════════════════════════╕\n// │ Color       │ Meaning                                         │\n// ├─────────────┼─────────────────────────────────────────────────┤\n// │ WHITE*      │ Unprocessed                                     │\n// │ BLACK*      │ Processed                                       │\n// │ GRAY        │ Processed with unprocessed children             │\n// │ TRANSPARENT │ Manually pinned (always reachable)              │\n// └─────────────┴─────────────────────────────────────────────────┘\n// * flipped between cycles\n\n// @ts-ignore: decorator\n@lazy var white = 0;\n// @ts-ignore: decorator\n@inline const gray = 2;\n// @ts-ignore: decorator\n@inline const transparent = 3;\n// @ts-ignore: decorator\n@inline const COLOR_MASK = 3;\n\n/** Size in memory of all objects currently managed by the GC. */\n// @ts-ignore: decorator\n@lazy var total: usize = 0;\n\n/** Currently transitioning from SWEEP to MARK state. */\n// @ts-ignore: decorator\n@inline const STATE_IDLE = 0;\n/** Currently marking reachable objects. */\n// @ts-ignore: decorator\n@inline const STATE_MARK = 1;\n/** Currently sweeping unreachable objects. */\n// @ts-ignore: decorator\n@inline const STATE_SWEEP = 2;\n/** Current collector state. */\n// @ts-ignore: decorator\n@lazy var state = STATE_IDLE;\n\n// @ts-ignore: decorator\n@lazy var fromSpace = initLazy(changetype<Object>(memory.data(offsetof<Object>())));\n// @ts-ignore: decorator\n@lazy var toSpace = initLazy(changetype<Object>(memory.data(offsetof<Object>())));\n// @ts-ignore: decorator\n@lazy var pinSpace = initLazy(changetype<Object>(memory.data(offsetof<Object>())));\n// @ts-ignore: decorator\n@lazy var iter: Object; // null\n\nfunction initLazy(space: Object): Object {\n  space.nextWithColor = changetype<usize>(space);\n  space.prev = space;\n  return space;\n}\n\n/** Visit cookie indicating scanning of an object. */\n// @ts-ignore: decorator\n@inline const VISIT_SCAN = 0;\n\n// ╒═══════════════ Managed object layout (32-bit) ════════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤\n// │                      Memory manager block                     │\n// ╞═══════════════════════════════════════════════════════════╤═══╡\n// │                              next                         │ C │ = nextWithColor\n// ├───────────────────────────────────────────────────────────┴───┤\n// │                              prev                             │\n// ├───────────────────────────────────────────────────────────────┤\n// │                              rtId                             │\n// ├───────────────────────────────────────────────────────────────┤\n// │                              rtSize                           │\n// ╞>ptr═══════════════════════════════════════════════════════════╡\n// │                               ...                             │\n// C: color\n\n/** Represents a managed object in memory, consisting of a header followed by the object's data. */\n@unmanaged class Object extends BLOCK {\n  /** Pointer to the next object with color flags stored in the alignment bits. */\n  nextWithColor: usize; // *u32\n  /** Pointer to the previous object. */\n  prev: Object; // *u32\n  /** Runtime id. */\n  rtId: u32;\n  /** Runtime size. */\n  rtSize: u32;\n\n  /** Gets the pointer to the next object. */\n  get next(): Object {\n    return changetype<Object>(this.nextWithColor & ~COLOR_MASK);\n  }\n\n  /** Sets the pointer to the next object. */\n  set next(obj: Object) {\n    this.nextWithColor = changetype<usize>(obj) | (this.nextWithColor & COLOR_MASK);\n  }\n\n  /** Gets this object's color. */\n  get color(): i32 {\n    return i32(this.nextWithColor & COLOR_MASK);\n  }\n\n  /** Sets this object's color. */\n  set color(color: i32) {\n    this.nextWithColor = (this.nextWithColor & ~COLOR_MASK) | color;\n  }\n\n  /** Gets the size of this object in memory. */\n  get size(): usize {\n    return BLOCK_OVERHEAD + (this.mmInfo & ~3);\n  }\n\n  /** Tests if this object is pointerfree. */\n  get isPointerfree(): bool {\n    var rtId = this.rtId;\n    return rtId <= idof<string>() || (__typeinfo(rtId) & TypeinfoFlags.POINTERFREE) != 0;\n  }\n\n  /** Unlinks this object from its list. */\n  unlink(): void {\n    var next = this.next;\n    if (next == null) {\n      if (DEBUG) assert(this.prev == null && changetype<usize>(this) < __heap_base);\n      return; // static data not yet linked\n    }\n    var prev = this.prev;\n    if (DEBUG) assert(prev);\n    next.prev = prev;\n    prev.next = next;\n  }\n\n  /** Links this object to the specified list, with the given color. */\n  linkTo(list: Object, withColor: i32): void {\n    let prev = list.prev;\n    this.nextWithColor = changetype<usize>(list) | withColor;\n    this.prev = prev;\n    prev.next = this;\n    list.prev = this;\n  }\n\n  /** Marks this object as gray, that is reachable with unscanned children. */\n  makeGray(): void {\n    if (this == iter) iter = assert(this.prev);\n    this.unlink();\n    this.linkTo(toSpace, this.isPointerfree ? i32(!white) : gray);\n  }\n}\n\n/** Visits all objects considered to be program roots. */\nfunction visitRoots(cookie: u32): void {\n  __visit_globals(cookie);\n  var pn = pinSpace;\n  var iter = pn.next;\n  while (iter != pn) {\n    if (DEBUG) assert(iter.color == transparent);\n    __visit_members(changetype<usize>(iter) + TOTAL_OVERHEAD, cookie);\n    iter = iter.next;\n  }\n}\n\n/** Visits all objects on the stack. */\nfunction visitStack(cookie: u32): void {\n  var ptr = __stack_pointer;\n  while (ptr < __heap_base) {\n    __visit(load<usize>(ptr), cookie);\n    ptr += sizeof<usize>();\n  }\n}\n\n/** Performs a single step according to the current state. */\nfunction step(): usize {\n  // Magic constants responsible for pause times. Obtained experimentally\n  // using the compiler compiling itself. 2048 budget pro run by default.\n  const MARKCOST = isDefined(ASC_GC_MARKCOST) ? ASC_GC_MARKCOST : 1;\n  const SWEEPCOST = isDefined(ASC_GC_SWEEPCOST) ? ASC_GC_SWEEPCOST : 10;\n  var obj: Object;\n  switch (state) {\n    case STATE_IDLE: {\n      state = STATE_MARK;\n      visitCount = 0;\n      visitRoots(VISIT_SCAN);\n      iter = toSpace;\n      return visitCount * MARKCOST;\n    }\n    case STATE_MARK: {\n      let black = i32(!white);\n      obj = iter.next;\n      while (obj != toSpace) {\n        iter = obj;\n        if (obj.color != black) { // skip already-blacks (pointerfree)\n          obj.color = black;\n          visitCount = 0;\n          __visit_members(changetype<usize>(obj) + TOTAL_OVERHEAD, VISIT_SCAN);\n          return visitCount * MARKCOST;\n        }\n        obj = obj.next;\n      }\n      visitCount = 0;\n      visitRoots(VISIT_SCAN);\n      obj = iter.next;\n      if (obj == toSpace) {\n        visitStack(VISIT_SCAN);\n        obj = iter.next;\n        while (obj != toSpace) {\n          if (obj.color != black) {\n            obj.color = black;\n            __visit_members(changetype<usize>(obj) + TOTAL_OVERHEAD, VISIT_SCAN);\n          }\n          obj = obj.next;\n        }\n        let from = fromSpace;\n        fromSpace = toSpace;\n        toSpace = from;\n        white = black;\n        iter = from.next;\n        state = STATE_SWEEP;\n      }\n      return visitCount * MARKCOST;\n    }\n    case STATE_SWEEP: {\n      obj = iter;\n      if (obj != toSpace) {\n        iter = obj.next;\n        if (DEBUG) assert(obj.color == i32(!white)); // old white\n        free(obj);\n        return SWEEPCOST;\n      }\n      toSpace.nextWithColor = changetype<usize>(toSpace);\n      toSpace.prev = toSpace;\n      state = STATE_IDLE;\n      break;\n    }\n  }\n  return 0;\n}\n\n/** Frees an object. */\nfunction free(obj: Object): void {\n  if (changetype<usize>(obj) < __heap_base) {\n    obj.nextWithColor = 0; // may become linked again\n    obj.prev = changetype<Object>(0);\n  } else {\n    total -= obj.size;\n    if (isDefined(__finalize)) {\n      __finalize(changetype<usize>(obj) + TOTAL_OVERHEAD);\n    }\n    __free(changetype<usize>(obj) + BLOCK_OVERHEAD);\n  }\n}\n\n// Garbage collector interface\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __new(size: usize, id: i32): usize {\n  if (size >= OBJECT_MAXSIZE) throw new Error(E_ALLOCATION_TOO_LARGE);\n  if (total >= threshold) interrupt();\n  var obj = changetype<Object>(__alloc(OBJECT_OVERHEAD + size) - BLOCK_OVERHEAD);\n  obj.rtId = id;\n  obj.rtSize = <u32>size;\n  obj.linkTo(fromSpace, white); // inits next/prev\n  total += obj.size;\n  var ptr = changetype<usize>(obj) + TOTAL_OVERHEAD;\n  // may be visited before being fully initialized, so must fill\n  memory.fill(ptr, 0, size);\n  return ptr;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __renew(oldPtr: usize, size: usize): usize {\n  var oldObj = changetype<Object>(oldPtr - TOTAL_OVERHEAD);\n  // Update object size if its block is large enough\n  if (size <= (oldObj.mmInfo & ~3) - OBJECT_OVERHEAD) {\n    oldObj.rtSize = <u32>size;\n    return oldPtr;\n  }\n  // If not the same object anymore, we have to move it move it due to the\n  // shadow stack potentially still referencing the old object\n  var newPtr = __new(size, oldObj.rtId);\n  memory.copy(newPtr, oldPtr, min(size, oldObj.rtSize));\n  return newPtr;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __link(parentPtr: usize, childPtr: usize, expectMultiple: bool): void {\n  // Write barrier is unnecessary if non-incremental\n  if (!childPtr) return;\n  if (DEBUG) assert(parentPtr);\n  var child = changetype<Object>(childPtr - TOTAL_OVERHEAD);\n  if (child.color == white) {\n    let parent = changetype<Object>(parentPtr - TOTAL_OVERHEAD);\n    let parentColor = parent.color;\n    if (parentColor == i32(!white)) {\n      // Maintain the invariant that no black object may point to a white object.\n      if (expectMultiple) {\n        // Move the barrier \"backward\". Suitable for containers receiving multiple stores.\n        // Avoids a barrier for subsequent objects stored into the same container.\n        parent.makeGray();\n      } else {\n        // Move the barrier \"forward\". Suitable for objects receiving isolated stores.\n        child.makeGray();\n      }\n    } else if (parentColor == transparent && state == STATE_MARK) {\n      // Pinned objects are considered 'black' during the mark phase.\n      child.makeGray();\n    }\n  }\n}\n\n// @ts-ignore: decorator\n@lazy var visitCount = 0;\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __visit(ptr: usize, cookie: i32): void {\n  if (!ptr) return;\n  let obj = changetype<Object>(ptr - TOTAL_OVERHEAD);\n  if (RTRACE) if (!onvisit(obj)) return;\n  if (obj.color == white) {\n    obj.makeGray();\n    ++visitCount;\n  }\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __pin(ptr: usize): usize {\n  if (ptr) {\n    let obj = changetype<Object>(ptr - TOTAL_OVERHEAD);\n    if (obj.color == transparent) {\n      throw new Error(E_ALREADY_PINNED);\n    }\n    obj.unlink(); // from fromSpace\n    obj.linkTo(pinSpace, transparent);\n  }\n  return ptr;\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __unpin(ptr: usize): void {\n  if (!ptr) return;\n  var obj = changetype<Object>(ptr - TOTAL_OVERHEAD);\n  if (obj.color != transparent) {\n    throw new Error(E_NOT_PINNED);\n  }\n  if (state == STATE_MARK) {\n    // We may be right at the point after marking roots for the second time and\n    // entering the sweep phase, in which case the object would be missed if it\n    // is not only pinned but also a root. Make sure it isn't missed.\n    obj.makeGray();\n  } else {\n    obj.unlink();\n    obj.linkTo(fromSpace, white);\n  }\n}\n\n// @ts-ignore: decorator\n@global @unsafe\nexport function __collect(): void {\n  if (TRACE) trace(\"GC (full) at\", 1, total);\n  if (state > STATE_IDLE) {\n    // finish current cycle\n    while (state != STATE_IDLE) step();\n  }\n  // perform a full cycle\n  step();\n  while (state != STATE_IDLE) step();\n  threshold = <usize>(<u64>total * IDLEFACTOR / 100) + GRANULARITY;\n  if (TRACE) trace(\"GC (full) done at cur/max\", 2, total, memory.size() << 16);\n  if (RTRACE || PROFILE) oncollect(total);\n}\n\n// Garbage collector automation\n\n/** How often to interrupt. The default of 1024 means \"interrupt each 1024 bytes allocated\". */\n// @ts-ignore: decorator\n@inline const GRANULARITY: usize = isDefined(ASC_GC_GRANULARITY) ? ASC_GC_GRANULARITY : 1024;\n/** How long to interrupt. The default of 200% means \"run at double the speed of allocations\". */\n// @ts-ignore: decorator\n@inline const STEPFACTOR: usize = isDefined(ASC_GC_SWEEPFACTOR) ? ASC_GC_SWEEPFACTOR : 200;\n/** How long to idle. The default of 200% means \"wait for memory to double before kicking in again\". */\n// @ts-ignore: decorator\n@inline const IDLEFACTOR: usize = isDefined(ASC_GC_IDLEFACTOR) ? ASC_GC_IDLEFACTOR : 200;\n\n/** Threshold of objects for the next scheduled GC step. */\n// @ts-ignore: decorator\n@lazy var threshold: usize = GRANULARITY;\n\n/** Performs a reasonable amount of incremental GC steps. */\nfunction interrupt(): void {\n  if (PROFILE) oninterrupt(total);\n  if (TRACE) trace(\"GC (auto) at\", 1, total);\n  var budget: isize = GRANULARITY * STEPFACTOR / 100;\n  do {\n    budget -= step();\n    if (state == STATE_IDLE) {\n      if (TRACE) trace(\"└ GC (auto) done at cur/max\", 2, total, memory.size() << 16);\n      threshold = <usize>(<u64>total * IDLEFACTOR / 100) + GRANULARITY;\n      if (PROFILE) onyield(total);\n      return;\n    }\n  } while (budget > 0);\n  if (TRACE) trace(\"└ GC (auto) ongoing at\", 1, total);\n  threshold = total + GRANULARITY * usize(total - threshold < GRANULARITY);\n  if (PROFILE) onyield(total);\n}\n","// The entry file of your WebAssembly module.\n\nexport function midpoint(a: i32, b: i32): i32 {\n  return a/2 + b/2;\n}\n"]}